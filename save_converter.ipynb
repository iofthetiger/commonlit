{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting saves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forgebox.imports import *\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS = Path(\"/nvme/GCI/public/lit/weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"roberta-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE = WEIGHTS/\"rbt_lg_0725_155121\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_configs(tag, save):\n",
    "    config = AutoConfig.from_pretrained(tag)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tag)\n",
    "    tokenizer.save_pretrained(save/\"tokenizer\")\n",
    "    config.save_pretrained(save/\"config\")\n",
    "    return tokenizer, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, config = save_configs(tag, SAVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bert_cased_0724_193954',\n",
       " 'rbt_lg_0725_155121',\n",
       " 'rbt_lg_finer_0725_160941',\n",
       " 'bert_buc_0724_194410',\n",
       " 'bert_buc_0725_002308',\n",
       " 'bert_0724_193402',\n",
       " 'bert_0724_231826']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WEIGHTS.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitLM(nn.Module):\n",
    "    def __init__(self, base):\n",
    "        super().__init__()\n",
    "        self.base =  base\n",
    "        self.learning_rate=1e-3\n",
    "        self.config = self.base.config\n",
    "        self.reg = nn.Linear(base.config.hidden_size, 1)\n",
    "        self.crit = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        vec  =self.base(x).last_hidden_state[:,0,:]\n",
    "        return self.reg(vec)\n",
    "    \n",
    "    def inference(\n",
    "        lit_model, model_weights:Path, data_loader:DataLoader, filename:str\n",
    "    ) -> None:\n",
    "        lit_model.load_state_dict(torch.load(str(model_weights)), strict=False)\n",
    "        lit_model = lit_model.eval()\n",
    "        lit_model = lit_model.cuda()\n",
    "        results = []\n",
    "        for batch_idx, batch in tqdm(enumerate(data_loader), leave=False):\n",
    "            ids = batch[\"id\"]\n",
    "            x = batch[\"excerpt\"].cuda()\n",
    "            with torch.no_grad():\n",
    "                y_ = lit_model(x)[:,0].detach().cpu().numpy()\n",
    "            results.append(pd.DataFrame({\"id\":ids, \"target\":y_}))\n",
    "        pd.concat(results).to_csv(filename, index=False)\n",
    "        lit_model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ckpt in list(i for i in SAVE.iterdir() if i.name[-5:]==\".ckpt\"):\n",
    "    state = torch.load(ckpt, map_location='cpu')['state_dict']\n",
    "    torch.save(state, ckpt.parent/(ckpt.name.replace(\"=\",\"-\").replace(\".ckpt\",\".h5\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LitLM(AutoModel.from_config(config)).load_state_dict(torch.load(ckpt, map_location='cpu')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config\t\t\t      epoch-20-val_loss-0.27fd1.h5  tokenizer\r\n",
      "epoch-10-val_loss-0.26fd0.h5  epoch-5-val_loss-0.30fd2.h5\r\n",
      "epoch-11-val_loss-0.31fd3.h5  epoch-9-val_loss-0.25fd4.h5\r\n"
     ]
    }
   ],
   "source": [
    "for i in SAVE.iterdir():\n",
    "    if i.name[-5:]==\".ckpt\":\n",
    "        os.system(f\"rm -f {i}\")\n",
    "        \n",
    "!ls {SAVE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data package template written to: /nvme/GCI/public/lit/weights/rbt_lg_0725_155121/dataset-metadata.json\r\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets init -p {SAVE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"title\": \"INSERT_TITLE_HERE\",\r\n",
      "  \"id\": \"raynardj/INSERT_SLUG_HERE\",\r\n",
      "  \"licenses\": [\r\n",
      "    {\r\n",
      "      \"name\": \"CC0-1.0\"\r\n",
      "    }\r\n",
      "  ]\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat {SAVE/\"dataset-metadata.json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /nvme/GCI/public/lit/weights/rbt_lg_0725_155121/dataset-metadata.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile {SAVE/\"dataset-metadata.json\"}\n",
    "{\n",
    "  \"title\": \"rbt_lg_0725_155121\",\n",
    "  \"id\": \"raynardj/rbt-lg-0725-155121\",\n",
    "  \"licenses\": [\n",
    "    {\n",
    "      \"name\": \"CC0-1.0\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting upload for file tokenizer.tar\n",
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.6)\n",
      "100%|███████████████████████████████████████| 2.50M/2.50M [00:05<00:00, 474kB/s]\n",
      "Upload successful: tokenizer.tar (2MB)\n",
      "Starting upload for file epoch-9-val_loss-0.25fd4.h5\n",
      "100%|██████████████████████████████████████| 1.32G/1.32G [20:25<00:00, 1.16MB/s]\n",
      "Upload successful: epoch-9-val_loss-0.25fd4.h5 (1GB)\n",
      "Starting upload for file config.tar\n",
      "100%|██████████████████████████████████████| 10.0k/10.0k [00:03<00:00, 2.65kB/s]\n",
      "Upload successful: config.tar (10KB)\n",
      "Starting upload for file epoch-10-val_loss-0.26fd0.h5\n",
      "100%|██████████████████████████████████████| 1.32G/1.32G [20:27<00:00, 1.16MB/s]\n",
      "Upload successful: epoch-10-val_loss-0.26fd0.h5 (1GB)\n",
      "Starting upload for file epoch-20-val_loss-0.27fd1.h5\n",
      "100%|██████████████████████████████████████| 1.32G/1.32G [20:40<00:00, 1.15MB/s]\n",
      "Upload successful: epoch-20-val_loss-0.27fd1.h5 (1GB)\n",
      "Starting upload for file epoch-11-val_loss-0.31fd3.h5\n",
      "100%|██████████████████████████████████████| 1.32G/1.32G [20:20<00:00, 1.17MB/s]\n",
      "Upload successful: epoch-11-val_loss-0.31fd3.h5 (1GB)\n",
      "Starting upload for file epoch-5-val_loss-0.30fd2.h5\n",
      "100%|██████████████████████████████████████| 1.32G/1.32G [20:43<00:00, 1.14MB/s]\n",
      "Upload successful: epoch-5-val_loss-0.30fd2.h5 (1GB)\n",
      "Your public Dataset is being created. Please check progress at /api/v1/datasets/status//raynardj/rbt-lg-0725-155121\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets create -r tar -u -p {SAVE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nvme/GCI/public/lit/weights/bert_0724_231826:\r\n",
      "config\t\t\t      epoch-15-val_loss-0.30fd2.h5\r\n",
      "dataset-metadata.json\t      epoch-16-val_loss-0.28fd0.h5\r\n",
      "epoch-10-val_loss-0.27fd4.h5  epoch-28-val_loss-0.29fd3.h5\r\n",
      "epoch-10-val_loss-0.31fd1.h5  tokenizer\r\n",
      "\r\n",
      "/nvme/GCI/public/lit/weights/bert_0724_231826/config:\r\n",
      "config.json\r\n",
      "\r\n",
      "/nvme/GCI/public/lit/weights/bert_0724_231826/tokenizer:\r\n",
      "special_tokens_map.json  tokenizer_config.json\ttokenizer.json\tvocab.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -R {SAVE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
