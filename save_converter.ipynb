{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting saves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forgebox.imports import *\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS = Path(\"/nvme/GCI/public/lit/weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"roberta-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rblg_att_head_0725_212112',\n",
       " 'pre_rbt_bs',\n",
       " 'pre_rbtlg',\n",
       " 'MeanPooler_aug_28_171839',\n",
       " 'bert_cased_0724_193954',\n",
       " 'CLSMeanLater_26_155044',\n",
       " 'rbt_lg_0725_155121',\n",
       " 'MeanPooler_3e_28_154350',\n",
       " 'rblg_mean_0725_234256',\n",
       " 'MeanPooler_3e_28_141004',\n",
       " 'MeanPooler_base2_28_235651',\n",
       " 'WithAttnHead_base2_28_234832',\n",
       " 'CLSReg_base2_29_225830',\n",
       " 'pre_rbt_bs2',\n",
       " 'CLSReg_bs2pre_29_235936',\n",
       " 'rbt_combined_v1',\n",
       " 'rbt_lg_finer_0725_160941',\n",
       " 'MeanLater_26_155703',\n",
       " 'MeanPooler_ne_27_170538',\n",
       " 'CLSReg_26_185501',\n",
       " 'MeanPooler_base2_28_233227',\n",
       " 'WithAttnHead_bs2pre_29_150559',\n",
       " 'rblg_mean_0725_214714',\n",
       " 'bert_buc_0724_194410',\n",
       " 'MeanPooler_cyclr_27_232944',\n",
       " 'MeanPooler_3e_28_161158',\n",
       " 'pre_rbt_lg',\n",
       " 'PairCLS_bs2pre_30_113040',\n",
       " 'bert_buc_0725_002308',\n",
       " 'MeanPooler_ne_27_151237',\n",
       " 'pre_rbt_lg2',\n",
       " 'CLSReg_ft_27_111118',\n",
       " 'CLSReg_bs2pre_29_170744',\n",
       " 'WithAttnHead_base2_29_140328',\n",
       " 'MeanPooler_bs2pre_upk_30_105624',\n",
       " 'CLSReg_base2_29_232842',\n",
       " 'MeanPooler_3e_28_180243',\n",
       " 'pre_rbtbs']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WEIGHTS.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=4-val_loss=0.25fd2.ckpt  epoch=6-val_loss=0.27fd0.ckpt\r\n",
      "epoch=4-val_loss=0.31fd4.ckpt  epoch=7-val_loss=0.32fd3.ckpt\r\n",
      "epoch=5-val_loss=0.26fd1.ckpt\r\n"
     ]
    }
   ],
   "source": [
    "SAVE = WEIGHTS/\"PairCLS_bs2pre_30_113040\"\n",
    "\n",
    "!ls {SAVE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_configs(tag, save):\n",
    "    config = AutoConfig.from_pretrained(tag)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tag)\n",
    "    tokenizer.save_pretrained(save/\"tokenizer\")\n",
    "    config.save_pretrained(save/\"config\")\n",
    "    return tokenizer, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, config = save_configs(tag, SAVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.middle_features = hidden_dim\n",
    "\n",
    "        self.W = nn.Linear(in_features, hidden_dim)\n",
    "        self.V = nn.Linear(hidden_dim, 1)\n",
    "        self.out_features = hidden_dim\n",
    "\n",
    "    def forward(self, features):\n",
    "        att = torch.tanh(self.W(features))\n",
    "        score = self.V(att)\n",
    "        attention_weights = torch.softmax(score, dim=1)\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = torch.sum(context_vector, dim=1)\n",
    "\n",
    "        return context_vector\n",
    "\n",
    "class LitLM(nn.Module):\n",
    "    def __init__(self, base):\n",
    "        super().__init__()\n",
    "        self.base =  base\n",
    "        self.learning_rate=1e-3\n",
    "        self.config = self.base.config\n",
    "        self.reg = nn.Linear(base.config.hidden_size, 1)\n",
    "        self.crit = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        vec  =self.base(x).last_hidden_state[:,0,:]\n",
    "        return self.reg(vec)\n",
    "    \n",
    "    def inference(\n",
    "        lit_model, model_weights:Path, data_loader:DataLoader, filename:str\n",
    "    ) -> None:\n",
    "        lit_model.load_state_dict(torch.load(str(model_weights)), strict=False)\n",
    "        lit_model = lit_model.eval()\n",
    "        lit_model = lit_model.cuda()\n",
    "        results = []\n",
    "        for batch_idx, batch in tqdm(enumerate(data_loader), leave=False):\n",
    "            ids = batch[\"id\"]\n",
    "            x = batch[\"excerpt\"].cuda()\n",
    "            with torch.no_grad():\n",
    "                y_ = lit_model(x)[:,0].detach().cpu().numpy()\n",
    "            results.append(pd.DataFrame({\"id\":ids, \"target\":y_}))\n",
    "        pd.concat(results).to_csv(filename, index=False)\n",
    "        lit_model.cpu()\n",
    "        \n",
    "class LitLMAttn(nn.Module):\n",
    "    def __init__(self, base):\n",
    "        super().__init__()\n",
    "        self.base =  base\n",
    "        self.learning_rate=1e-4\n",
    "        self.config = self.base.config\n",
    "        self.head = AttentionHead(self.config.hidden_size, self.config.hidden_size)\n",
    "        self.dout = nn.Dropout(.1)\n",
    "        self.reg = nn.Linear(base.config.hidden_size, 1)\n",
    "        self.crit = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        vec  =self.base(x).last_hidden_state\n",
    "        return self.reg(self.dout(self.head(vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recur_dir(path:Path):\n",
    "    results = []\n",
    "    for p in path.iterdir():\n",
    "        if p.is_dir():\n",
    "            results+=recur_dir(p)\n",
    "        else:\n",
    "            results.append(p)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c635e44f7374c8e880199bd0f043ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for ckpt in tqdm(list(i for i in recur_dir(SAVE) if i.name[-5:]==\".ckpt\")):\n",
    "    state = torch.load(str(ckpt), map_location='cpu')['state_dict']\n",
    "    torch.save(state, str(ckpt.parent/(ckpt.name.replace(\"=\",\"-\").replace(\".ckpt\",\".h5\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LitLMAttn(AutoModel.from_config(config)).load_state_dict(torch.load(ckpt, map_location='cpu')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LitLM(AutoModel.from_config(config)).load_state_dict(torch.load(str(ckpt), map_location='cpu')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config\t\t\t     epoch-5-val_loss-0.26fd1.h5  tokenizer\r\n",
      "epoch-4-val_loss-0.25fd2.h5  epoch-6-val_loss-0.27fd0.h5\r\n",
      "epoch-4-val_loss-0.31fd4.h5  epoch-7-val_loss-0.32fd3.h5\r\n"
     ]
    }
   ],
   "source": [
    "for i in recur_dir(SAVE):\n",
    "    if i.name[-5:]==\".ckpt\":\n",
    "        os.system(f\"rm -f {i}\")\n",
    "        \n",
    "!ls {SAVE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data package template written to: /nvme/GCI/public/lit/weights/PairCLS_bs2pre_30_113040/dataset-metadata.json\r\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets init -p {SAVE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"title\": \"INSERT_TITLE_HERE\",\r\n",
      "  \"id\": \"raynardj/INSERT_SLUG_HERE\",\r\n",
      "  \"licenses\": [\r\n",
      "    {\r\n",
      "      \"name\": \"CC0-1.0\"\r\n",
      "    }\r\n",
      "  ]\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat {SAVE/\"dataset-metadata.json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /nvme/GCI/public/lit/weights/PairCLS_bs2pre_30_113040/dataset-metadata.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile {SAVE/\"dataset-metadata.json\"}\n",
    "{\n",
    "  \"title\": \"PR_bs2pre_30_113040\",\n",
    "  \"id\": \"raynardj/pr-bs2pre-30-113040\",\n",
    "  \"licenses\": [\n",
    "    {\n",
    "      \"name\": \"CC0-1.0\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting upload for file epoch-4-val_loss-0.31fd4.h5\n",
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.6)\n",
      "100%|████████████████████████████████████████| 476M/476M [07:07<00:00, 1.17MB/s]\n",
      "Upload successful: epoch-4-val_loss-0.31fd4.h5 (476MB)\n",
      "Starting upload for file tokenizer.tar\n",
      "100%|███████████████████████████████████████| 2.50M/2.50M [00:05<00:00, 445kB/s]\n",
      "Upload successful: tokenizer.tar (2MB)\n",
      "Starting upload for file config.tar\n",
      "100%|██████████████████████████████████████| 10.0k/10.0k [00:05<00:00, 1.94kB/s]\n",
      "Upload successful: config.tar (10KB)\n",
      "Starting upload for file epoch-5-val_loss-0.26fd1.h5\n",
      "100%|████████████████████████████████████████| 476M/476M [07:10<00:00, 1.16MB/s]\n",
      "Upload successful: epoch-5-val_loss-0.26fd1.h5 (476MB)\n",
      "Starting upload for file epoch-4-val_loss-0.25fd2.h5\n",
      "100%|████████████████████████████████████████| 476M/476M [07:20<00:00, 1.13MB/s]\n",
      "Upload successful: epoch-4-val_loss-0.25fd2.h5 (476MB)\n",
      "Starting upload for file epoch-7-val_loss-0.32fd3.h5\n",
      "100%|████████████████████████████████████████| 476M/476M [07:14<00:00, 1.15MB/s]\n",
      "Upload successful: epoch-7-val_loss-0.32fd3.h5 (476MB)\n",
      "Starting upload for file epoch-6-val_loss-0.27fd0.h5\n",
      "100%|████████████████████████████████████████| 476M/476M [07:25<00:00, 1.12MB/s]\n",
      "Upload successful: epoch-6-val_loss-0.27fd0.h5 (476MB)\n",
      "Your public Dataset is being created. Please check progress at /api/v1/datasets/status//raynardj/pr-bs2pre-30-113040\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets create -r tar -u -p {SAVE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nvme/GCI/public/lit/weights/bert_0724_231826:\r\n",
      "config\t\t\t      epoch-15-val_loss-0.30fd2.h5\r\n",
      "dataset-metadata.json\t      epoch-16-val_loss-0.28fd0.h5\r\n",
      "epoch-10-val_loss-0.27fd4.h5  epoch-28-val_loss-0.29fd3.h5\r\n",
      "epoch-10-val_loss-0.31fd1.h5  tokenizer\r\n",
      "\r\n",
      "/nvme/GCI/public/lit/weights/bert_0724_231826/config:\r\n",
      "config.json\r\n",
      "\r\n",
      "/nvme/GCI/public/lit/weights/bert_0724_231826/tokenizer:\r\n",
      "special_tokens_map.json  tokenizer_config.json\ttokenizer.json\tvocab.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -R {SAVE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sub(SAVE):\n",
    "    for di in SAVE.iterdir():\n",
    "        if di.is_symlink():\n",
    "            os.system(f\"cp {SAVE}/dataset-metadata.json {di}/dataset-metadata.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sub(SAVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
