{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting saves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from forgebox.imports import *\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHTS = Path(\"/nvme/GCI/public/lit/weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"roberta-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rblg_att_head_0725_212112',\n",
       " 'bert_cased_0724_193954',\n",
       " 'rbt_lg_0725_155121',\n",
       " 'rblg_mean_0725_234256',\n",
       " 'rbt_lg_finer_0725_160941',\n",
       " 'rblg_mean_0725_214714',\n",
       " 'bert_buc_0724_194410',\n",
       " 'bert_buc_0725_002308',\n",
       " 'bert_0724_193402',\n",
       " 'bert_0724_231826']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WEIGHTS.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=10-val_loss=0.34fd1.ckpt\tepoch=8-val_loss=0.27fd4.ckpt\r\n",
      "epoch=1-val_loss=0.23fd3.ckpt\tepoch=9-val_loss=0.29fd0.ckpt\r\n",
      "epoch=1-val_loss=0.32fd2.ckpt\r\n"
     ]
    }
   ],
   "source": [
    "SAVE = WEIGHTS/\"rblg_mean_0725_234256\"\n",
    "\n",
    "!ls {SAVE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_configs(tag, save):\n",
    "    config = AutoConfig.from_pretrained(tag)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(tag)\n",
    "    tokenizer.save_pretrained(save/\"tokenizer\")\n",
    "    config.save_pretrained(save/\"config\")\n",
    "    return tokenizer, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, config = save_configs(tag, SAVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, in_features, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.middle_features = hidden_dim\n",
    "\n",
    "        self.W = nn.Linear(in_features, hidden_dim)\n",
    "        self.V = nn.Linear(hidden_dim, 1)\n",
    "        self.out_features = hidden_dim\n",
    "\n",
    "    def forward(self, features):\n",
    "        att = torch.tanh(self.W(features))\n",
    "        score = self.V(att)\n",
    "        attention_weights = torch.softmax(score, dim=1)\n",
    "        context_vector = attention_weights * features\n",
    "        context_vector = torch.sum(context_vector, dim=1)\n",
    "\n",
    "        return context_vector\n",
    "\n",
    "class LitLM(nn.Module):\n",
    "    def __init__(self, base):\n",
    "        super().__init__()\n",
    "        self.base =  base\n",
    "        self.learning_rate=1e-3\n",
    "        self.config = self.base.config\n",
    "        self.reg = nn.Linear(base.config.hidden_size, 1)\n",
    "        self.crit = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        vec  =self.base(x).last_hidden_state[:,0,:]\n",
    "        return self.reg(vec)\n",
    "    \n",
    "    def inference(\n",
    "        lit_model, model_weights:Path, data_loader:DataLoader, filename:str\n",
    "    ) -> None:\n",
    "        lit_model.load_state_dict(torch.load(str(model_weights)), strict=False)\n",
    "        lit_model = lit_model.eval()\n",
    "        lit_model = lit_model.cuda()\n",
    "        results = []\n",
    "        for batch_idx, batch in tqdm(enumerate(data_loader), leave=False):\n",
    "            ids = batch[\"id\"]\n",
    "            x = batch[\"excerpt\"].cuda()\n",
    "            with torch.no_grad():\n",
    "                y_ = lit_model(x)[:,0].detach().cpu().numpy()\n",
    "            results.append(pd.DataFrame({\"id\":ids, \"target\":y_}))\n",
    "        pd.concat(results).to_csv(filename, index=False)\n",
    "        lit_model.cpu()\n",
    "        \n",
    "class LitLMAttn(nn.Module):\n",
    "    def __init__(self, base):\n",
    "        super().__init__()\n",
    "        self.base =  base\n",
    "        self.learning_rate=1e-4\n",
    "        self.config = self.base.config\n",
    "        self.head = AttentionHead(self.config.hidden_size, self.config.hidden_size)\n",
    "        self.dout = nn.Dropout(.1)\n",
    "        self.reg = nn.Linear(base.config.hidden_size, 1)\n",
    "        self.crit = nn.MSELoss()\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        vec  =self.base(x).last_hidden_state\n",
    "        return self.reg(self.dout(self.head(vec)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ckpt in list(i for i in SAVE.iterdir() if i.name[-5:]==\".ckpt\"):\n",
    "    state = torch.load(ckpt, map_location='cpu')['state_dict']\n",
    "    torch.save(state, ckpt.parent/(ckpt.name.replace(\"=\",\"-\").replace(\".ckpt\",\".h5\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LitLMAttn(AutoModel.from_config(config)).load_state_dict(torch.load(ckpt, map_location='cpu')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LitLM(AutoModel.from_config(config)).load_state_dict(torch.load(ckpt, map_location='cpu')['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config\t\t\t      epoch-1-val_loss-0.32fd2.h5  tokenizer\r\n",
      "epoch-10-val_loss-0.34fd1.h5  epoch-8-val_loss-0.27fd4.h5\r\n",
      "epoch-1-val_loss-0.23fd3.h5   epoch-9-val_loss-0.29fd0.h5\r\n"
     ]
    }
   ],
   "source": [
    "for i in SAVE.iterdir():\n",
    "    if i.name[-5:]==\".ckpt\":\n",
    "        os.system(f\"rm -f {i}\")\n",
    "        \n",
    "!ls {SAVE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data package template written to: /nvme/GCI/public/lit/weights/rblg_mean_0725_234256/dataset-metadata.json\r\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets init -p {SAVE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "  \"title\": \"INSERT_TITLE_HERE\",\r\n",
      "  \"id\": \"raynardj/INSERT_SLUG_HERE\",\r\n",
      "  \"licenses\": [\r\n",
      "    {\r\n",
      "      \"name\": \"CC0-1.0\"\r\n",
      "    }\r\n",
      "  ]\r\n",
      "}"
     ]
    }
   ],
   "source": [
    "!cat {SAVE/\"dataset-metadata.json\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /nvme/GCI/public/lit/weights/rblg_mean_0725_234256/dataset-metadata.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile {SAVE/\"dataset-metadata.json\"}\n",
    "{\n",
    "  \"title\": \"rblg_mean_0725_234256\",\n",
    "  \"id\": \"raynardj/rblg-mean-0725-234256\",\n",
    "  \"licenses\": [\n",
    "    {\n",
    "      \"name\": \"CC0-1.0\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting upload for file tokenizer.tar\n",
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.6)\n",
      "100%|███████████████████████████████████████| 2.50M/2.50M [00:07<00:00, 366kB/s]\n",
      "Upload successful: tokenizer.tar (2MB)\n",
      "Starting upload for file config.tar\n",
      "100%|██████████████████████████████████████| 10.0k/10.0k [00:04<00:00, 2.23kB/s]\n",
      "Upload successful: config.tar (10KB)\n",
      "Starting upload for file epoch-1-val_loss-0.23fd3.h5\n",
      "100%|██████████████████████████████████████| 1.32G/1.32G [20:17<00:00, 1.17MB/s]\n",
      "Upload successful: epoch-1-val_loss-0.23fd3.h5 (1GB)\n",
      "Starting upload for file epoch-10-val_loss-0.34fd1.h5\n",
      "100%|██████████████████████████████████████| 1.32G/1.32G [20:25<00:00, 1.16MB/s]\n",
      "Upload successful: epoch-10-val_loss-0.34fd1.h5 (1GB)\n",
      "Starting upload for file epoch-9-val_loss-0.29fd0.h5\n",
      "100%|██████████████████████████████████████| 1.32G/1.32G [20:15<00:00, 1.17MB/s]\n",
      "Upload successful: epoch-9-val_loss-0.29fd0.h5 (1GB)\n",
      "Starting upload for file epoch-1-val_loss-0.32fd2.h5\n",
      "100%|██████████████████████████████████████| 1.32G/1.32G [20:13<00:00, 1.17MB/s]\n",
      "Upload successful: epoch-1-val_loss-0.32fd2.h5 (1GB)\n",
      "Starting upload for file epoch-8-val_loss-0.27fd4.h5\n",
      "100%|██████████████████████████████████████| 1.32G/1.32G [20:20<00:00, 1.16MB/s]\n",
      "Upload successful: epoch-8-val_loss-0.27fd4.h5 (1GB)\n",
      "Your public Dataset is being created. Please check progress at /api/v1/datasets/status//raynardj/rblg-mean-0725-234256\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets create -r tar -u -p {SAVE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/nvme/GCI/public/lit/weights/bert_0724_231826:\r\n",
      "config\t\t\t      epoch-15-val_loss-0.30fd2.h5\r\n",
      "dataset-metadata.json\t      epoch-16-val_loss-0.28fd0.h5\r\n",
      "epoch-10-val_loss-0.27fd4.h5  epoch-28-val_loss-0.29fd3.h5\r\n",
      "epoch-10-val_loss-0.31fd1.h5  tokenizer\r\n",
      "\r\n",
      "/nvme/GCI/public/lit/weights/bert_0724_231826/config:\r\n",
      "config.json\r\n",
      "\r\n",
      "/nvme/GCI/public/lit/weights/bert_0724_231826/tokenizer:\r\n",
      "special_tokens_map.json  tokenizer_config.json\ttokenizer.json\tvocab.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls -R {SAVE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
